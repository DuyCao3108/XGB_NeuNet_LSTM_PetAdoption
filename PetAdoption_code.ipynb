{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import math\n",
    "import sklearn \n",
    "import xgboost\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(r'C:\\Users\\Admin\\PetAdoption\\train\\train.csv')\n",
    "breed = pd.read_csv(r'C:\\Users\\Admin\\PetAdoption\\PetFinder-BreedLabels.csv')\n",
    "color = pd.read_csv(r'C:\\Users\\Admin\\PetAdoption\\PetFinder-ColorLabels.csv')\n",
    "state = pd.read_csv(r'C:\\Users\\Admin\\PetAdoption\\PetFinder-StateLabels.csv')\n",
    "test = pd.read_csv(r'C:\\Users\\Admin\\PetAdoption\\test\\test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "# Ignore all warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Or ignore specific warnings by category (e.g., FutureWarnings)\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Predicting using categorical and numerical data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########  DEFINING A FUNCTION THAT PREPARE CORRECT INPUT FOR MODEL #########\n",
    "def get_input(df, breed,color,state):\n",
    "    # Merging with other tables to get labels\n",
    "    df_drop = df.drop(['PhotoAmt','PetID','Description','VideoAmt','RescuerID','Name'],axis=1)\n",
    "    df_drop = df_drop.rename(columns={'Breed1':'BreedID'}).merge(breed, on=['BreedID','Type'],how='left').drop('BreedID',axis=1)\n",
    "    df_drop = df_drop.rename(columns={'Breed2':'BreedID'}).merge(breed, on=['BreedID','Type'],how='left').drop('BreedID',axis=1)\n",
    "    \n",
    "    for color_col in ['Color1','Color2','Color3']:\n",
    "        df_drop = df_drop.rename(columns={color_col: 'ColorID'}).merge(color, on ='ColorID', how = 'left').drop('ColorID',axis=1)\n",
    "    df_drop = df_drop.rename(columns={'State':'StateID'}).merge(state,on ='StateID', how = 'left').drop('StateID',axis=1)\n",
    "\n",
    "    # Get label of data to understand the context\n",
    "    label_dict = {\n",
    "        'Type': ['Not specified','Dog','Cat'],\n",
    "        'Gender': ['Not specified','Male','Female','Mixed'],\n",
    "        'FurLength': ['Not specified','Short','Medium','Long'],\n",
    "        'Vaccinated': ['Not specified','Yes','No'],\n",
    "        'Dewormed': ['Not specified','Yes','No'],\n",
    "        'Sterilized': ['Not specified','Yes','No'],\n",
    "        'Health': ['Not specified','Healthy','Minor Injury','Serious Injury'],\n",
    "        'MaturitySize': ['Not specified','Small','Medium','Large','Extra Large'],\n",
    "        'AdoptionSpeed': ['First_day', 'First_week', 'First_month', 'First_30_to_90_days', 'First_100_days']\n",
    "    }\n",
    "\n",
    "    for col in df_drop.columns:\n",
    "        if col in label_dict:\n",
    "            label_list = label_dict[col]\n",
    "            for number in range(len(label_list)):\n",
    "                df_drop[col][df_drop[col] == number] = label_list[number]\n",
    "    df_labeled = df_drop\n",
    "    df_dummy = pd.get_dummies(df_labeled,dtype=int)\n",
    "    \n",
    "    return df_dummy, df_labeled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train_eval = get_input(train,breed,color,state)[0] # take df_dum\n",
    "data_test = get_input(test,breed,color,state)[0] # take df_dum\n",
    "# Split train data to train - evaluate set:\n",
    "n_split = math.floor(data_train_eval.shape[0] * 0.8)\n",
    "data_train = data_train_eval.sample(n=len(data_train_eval),random_state=31,ignore_index=True) # shuffle data\n",
    "\n",
    "data_train = data_train_eval.iloc[:n_split,:]\n",
    "data_eval = data_train_eval.iloc[n_split:,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Predicting with XGBoost "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_multiple_models(data_train, data_eval):\n",
    "    # function that return 5 inputs (used to train on 5 outcome of the model):\n",
    "    def get_5_input(data):\n",
    "        data_dict = {}\n",
    "        y_list = ['AdoptionSpeed_First_day', 'AdoptionSpeed_First_week', 'AdoptionSpeed_First_month', 'AdoptionSpeed_First_30_to_90_days', 'AdoptionSpeed_First_100_days']\n",
    "        for y_target in y_list:\n",
    "            xdata = data.drop(y_list,axis=1)\n",
    "            ydata = data[y_target]\n",
    "            data_dict[y_target] = (xdata,ydata)\n",
    "        return data_dict\n",
    "    # use get_5_input fuction to get data dict for train and eval data:\n",
    "    data_train_dict = get_5_input(data_train)\n",
    "    data_eval_dict = get_5_input(data_eval)\n",
    "\n",
    "    # function that build, train 5 models: \n",
    "    def build_train_model(data_train_dict, data_eval_dict):\n",
    "        model_dict = {}\n",
    "        for target_data in data_train_dict.keys():\n",
    "            xtrain = data_train_dict[target_data][0]\n",
    "            ytrain = data_train_dict[target_data][1]\n",
    "            eval_set = data_eval_dict[target_data]\n",
    "            model = XGBClassifier()\n",
    "            model.fit(\n",
    "                xtrain, ytrain,\n",
    "                eval_set= [eval_set], \n",
    "                verbose = False\n",
    "            )\n",
    "            model_dict[target_data] = model\n",
    "        return model_dict\n",
    "    \n",
    "    # use build_train_model function to generate 5 models that predict 5 outcomes:\n",
    "    model_dict = build_train_model(data_train_dict, data_eval_dict)\n",
    "\n",
    "    return model_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get list of full columns\n",
    "full_columns_ordered = data_train.drop(\n",
    "        ['AdoptionSpeed_First_day', 'AdoptionSpeed_First_week', 'AdoptionSpeed_First_month', 'AdoptionSpeed_First_30_to_90_days', 'AdoptionSpeed_First_100_days']\n",
    "        , axis =1\n",
    "        ).columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function that prepare input data and predict:\n",
    "def prepare_predict(data, full_columns_ordered, model_dict):\n",
    "    # function that padding and re-ordering data's column to fit with columns used to train:\n",
    "    def input_columns_adjustment(data, full_columns_ordered):\n",
    "        # padding missing columns to current data\n",
    "        columns_that_appear_both = full_columns_ordered.isin(data.columns)\n",
    "        columns_that_are_missing_and_undefined = full_columns_ordered[columns_that_appear_both == 0]\n",
    "        df_with_missing_and_undefined_columns = pd.DataFrame(np.zeros((len(data),len(columns_that_are_missing_and_undefined))),\n",
    "                                                                columns = columns_that_are_missing_and_undefined)\n",
    "        if df_with_missing_and_undefined_columns.empty == True: return data[full_columns_ordered] # this line to fix the logical error of this function\n",
    "        else:\n",
    "            data = pd.concat([\n",
    "                data, df_with_missing_and_undefined_columns\n",
    "            ], axis=1)\n",
    "            # excluding cols that are not predefined and reordering data to match training data\n",
    "            data = data[full_columns_ordered]\n",
    "        return data\n",
    "    \n",
    "    # use input_columns_adjustment to preapre input data:\n",
    "    data_prepared = input_columns_adjustment(data, full_columns_ordered)\n",
    "\n",
    "    \n",
    "    # Predicting and generate df result\n",
    "    ## initiate df\n",
    "    y_pred_df_5 = pd.DataFrame(np.zeros((len(data_prepared),1)))\n",
    "    ## predict multiple times:\n",
    "    for model_y in model_dict.values():\n",
    "        y_pred = model_y.predict_proba(data_prepared)\n",
    "        y_pred_true = y_pred[:,1:]\n",
    "        y_pred_true = pd.DataFrame(y_pred_true)\n",
    "        y_pred_df_5 = pd.concat([y_pred_df_5,y_pred_true],axis = 1)\n",
    "    y_pred_df_5 = y_pred_df_5.iloc[:,1:]\n",
    "    y_pred_df_5.columns = model_dict.keys()\n",
    "\n",
    "\n",
    "    # get the column that has the highest percentage for each obseravtion\n",
    "    ## def a function that get most likely speed label and value for each obs\n",
    "    def get_max(x, ouput_option):\n",
    "        max_prob = 0\n",
    "        max_speed = 'column'\n",
    "        for col in y_pred_df_5.columns:\n",
    "            if x[col] > max_prob: \n",
    "                max_speed = col\n",
    "                max_prob = x[col]\n",
    "        if ouput_option == 'label':\n",
    "            return max_speed\n",
    "        if ouput_option == 'prob':\n",
    "            return max_prob\n",
    "    ## use get_max function to get most likely label and its prob\n",
    "    y_pred_df_5['Max prob'] = y_pred_df_5.apply(get_max,args = ['prob'], axis=1)\n",
    "    y_pred_df_5['Most likely label'] = y_pred_df_5.apply(get_max, args = ['label'], axis=1)\n",
    "    ## shorten result for better intepretation\n",
    "    y_pred_short = y_pred_df_5[['Max prob','Most likely label']]\n",
    "\n",
    "\n",
    "    ## Addition: predict and label (not just outputing probability):\n",
    "    y_pred_df_5_boolean = pd.DataFrame(np.zeros((len(data_prepared),1)))\n",
    "    for model_y in model_dict.values():\n",
    "        y_pred = pd.DataFrame(model_y.predict(data_prepared))\n",
    "        y_pred_df_5_boolean = pd.concat([y_pred_df_5_boolean,y_pred],axis = 1)\n",
    "    y_pred_df_5_boolean = y_pred_df_5_boolean.iloc[:,1:]\n",
    "    y_pred_df_5_boolean.columns = model_dict.keys()\n",
    "\n",
    "    print(\"input_shape: \", data.shape ,\"output_shape: \", data_prepared.shape)\n",
    "\n",
    "    return y_pred_short, y_pred_df_5, y_pred_df_5_boolean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Evaluate model's performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define function that caluculate average value for confusion matrix\n",
    "def get_total_confusion_matrix(label_predicted,label_real):\n",
    "    confusion_matrix_list = []\n",
    "    for y_class in ['AdoptionSpeed_First_day', 'AdoptionSpeed_First_week', 'AdoptionSpeed_First_month', 'AdoptionSpeed_First_30_to_90_days', 'AdoptionSpeed_First_100_days']:\n",
    "        predicted_y = label_predicted[y_class]\n",
    "        real_y = label_real[y_class]\n",
    "        confusion_matrix_list.append(confusion_matrix(real_y,predicted_y))\n",
    "    return sum(confusion_matrix_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def function to calculate metrics:\n",
    "def calculate_perform_metrics(total_confusion_matrix):\n",
    "    # get components\n",
    "    TP = total_confusion_matrix[1,1]\n",
    "    TN = total_confusion_matrix[0,0]\n",
    "    FP = total_confusion_matrix[0,1]\n",
    "    FN = total_confusion_matrix[1,0]\n",
    "    # calculate metrics\n",
    "    metric_dict ={\n",
    "        'accuracy': (TP+TN)/(TP+TN+FP+FN),\n",
    "        'precision': TP/(TP+FP),\n",
    "        'recall': TP/(TP+FN),\n",
    "        'F1': 2 * (TP/(TP+FP) * TP/(TP+FN)) / (TP/(TP+FP) + TP/(TP+FN)) #  2 * (precision * recall) / (precision + recall)\n",
    "    }\n",
    "    \n",
    "    return metric_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate model performance\n",
    "model_dict = training_multiple_models(data_train, data_eval)\n",
    "y_pred_short, y_pred_df_5, y_pred_df_5_boolean = prepare_predict(data_eval, full_columns_ordered, model_dict)\n",
    "# Get predicted label and real label\n",
    "label_predicted = y_pred_df_5_boolean\n",
    "label_real = data_eval[['AdoptionSpeed_First_day', 'AdoptionSpeed_First_week', 'AdoptionSpeed_First_month', 'AdoptionSpeed_First_30_to_90_days', 'AdoptionSpeed_First_100_days']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_confusion_matrix = get_total_confusion_matrix(label_predicted,label_real)\n",
    "print(total_confusion_matrix)\n",
    "\n",
    "# visualizing confusion matrix:\n",
    "sns.heatmap(total_confusion_matrix, annot=True, cmap=\"crest\", fmt='.4g')\n",
    "\n",
    "# calcualte metric dict \n",
    "metric_dict = calculate_perform_metrics(total_confusion_matrix)\n",
    "print(metric_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 Predicting with Neural network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3.1 Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11994, 367) (2999, 367) (11994, 5) (2999, 5) (3972, 269)\n"
     ]
    }
   ],
   "source": [
    "# get desired input\n",
    "data_train_eval = get_input(train, breed,color,state)[0] # take df_dum\n",
    "list_of_label = ['AdoptionSpeed_First_day', 'AdoptionSpeed_First_week', 'AdoptionSpeed_First_month', 'AdoptionSpeed_First_30_to_90_days', 'AdoptionSpeed_First_100_days']\n",
    "\n",
    "label_train_eval = data_train_eval[list_of_label]\n",
    "data_train_eval = data_train_eval.drop(list_of_label, axis = 1)\n",
    "\n",
    "data_test = get_input(test,breed,color,state)[0] # take df_dum\n",
    "\n",
    "# Split train data to train - evaluate set:\n",
    "n_split = math.floor(data_train_eval.shape[0] * 0.8)\n",
    "\n",
    "data_train = data_train_eval.iloc[:n_split,:]\n",
    "data_eval = data_train_eval.iloc[n_split:,:]\n",
    "\n",
    "label_train = label_train_eval.iloc[:n_split,:]\n",
    "label_eval = label_train_eval.iloc[n_split:,:]\n",
    "\n",
    "# print out shape\n",
    "print(\n",
    "    data_train.shape,\n",
    "    data_eval.shape,\n",
    "    label_train.shape,\n",
    "    label_eval.shape,\n",
    "    data_test.shape # data test need adjustment, already defined a function above\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    tf.keras.Input(shape=(data_train.shape[1],)),\n",
    "    tf.keras.layers.Dense(units=200),\n",
    "    tf.keras.layers.Dense(units=150),\n",
    "    tf.keras.layers.Dense(units=100),\n",
    "    tf.keras.layers.Dense(units=50),\n",
    "    tf.keras.layers.Dense(units=5, activation='softmax'),\n",
    "])\n",
    "\n",
    "model.compile(\n",
    "    loss= 'CategoricalCrossentropy',\n",
    "    optimizer= 'Adam',\n",
    "    metrics = ['Accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 1.9074 - Accuracy: 0.3211 - val_loss: 1.5042 - val_Accuracy: 0.3148\n",
      "Epoch 2/100\n",
      "375/375 [==============================] - 1s 1ms/step - loss: 1.4632 - Accuracy: 0.3464 - val_loss: 1.4124 - val_Accuracy: 0.3545\n",
      "Epoch 3/100\n",
      "375/375 [==============================] - 1s 1ms/step - loss: 1.4961 - Accuracy: 0.3458 - val_loss: 1.4196 - val_Accuracy: 0.3451\n",
      "Epoch 4/100\n",
      "375/375 [==============================] - 0s 1ms/step - loss: 1.4264 - Accuracy: 0.3559 - val_loss: 1.3958 - val_Accuracy: 0.3528\n",
      "Epoch 5/100\n",
      "375/375 [==============================] - 1s 1ms/step - loss: 1.4205 - Accuracy: 0.3598 - val_loss: 1.4045 - val_Accuracy: 0.3635\n",
      "Epoch 6/100\n",
      "375/375 [==============================] - 1s 1ms/step - loss: 1.4106 - Accuracy: 0.3655 - val_loss: 1.3899 - val_Accuracy: 0.3625\n",
      "Epoch 7/100\n",
      "375/375 [==============================] - 0s 1ms/step - loss: 1.4070 - Accuracy: 0.3681 - val_loss: 1.4507 - val_Accuracy: 0.3531\n",
      "Epoch 8/100\n",
      "375/375 [==============================] - 1s 1ms/step - loss: 1.4212 - Accuracy: 0.3598 - val_loss: 1.4078 - val_Accuracy: 0.3548\n",
      "Epoch 9/100\n",
      "375/375 [==============================] - 1s 1ms/step - loss: 1.4042 - Accuracy: 0.3709 - val_loss: 1.4056 - val_Accuracy: 0.3615\n",
      "Epoch 10/100\n",
      "375/375 [==============================] - 0s 1ms/step - loss: 1.3924 - Accuracy: 0.3716 - val_loss: 1.4288 - val_Accuracy: 0.3521\n",
      "Epoch 11/100\n",
      "375/375 [==============================] - 0s 1ms/step - loss: 1.3921 - Accuracy: 0.3794 - val_loss: 1.4071 - val_Accuracy: 0.3625\n",
      "Epoch 12/100\n",
      "375/375 [==============================] - 1s 1ms/step - loss: 1.3848 - Accuracy: 0.3754 - val_loss: 1.4274 - val_Accuracy: 0.3588\n",
      "Epoch 13/100\n",
      "375/375 [==============================] - 0s 1ms/step - loss: 1.3995 - Accuracy: 0.3753 - val_loss: 1.4009 - val_Accuracy: 0.3558\n",
      "Epoch 14/100\n",
      "375/375 [==============================] - 1s 1ms/step - loss: 1.3848 - Accuracy: 0.3757 - val_loss: 1.4047 - val_Accuracy: 0.3631\n",
      "Epoch 15/100\n",
      "375/375 [==============================] - 0s 1ms/step - loss: 1.3891 - Accuracy: 0.3715 - val_loss: 1.4025 - val_Accuracy: 0.3611\n",
      "Epoch 16/100\n",
      "375/375 [==============================] - 0s 1ms/step - loss: 1.3877 - Accuracy: 0.3796 - val_loss: 1.3991 - val_Accuracy: 0.3531\n",
      "Epoch 17/100\n",
      "375/375 [==============================] - 1s 1ms/step - loss: 1.3841 - Accuracy: 0.3755 - val_loss: 1.4084 - val_Accuracy: 0.3505\n",
      "Epoch 18/100\n",
      "375/375 [==============================] - 0s 1ms/step - loss: 1.3822 - Accuracy: 0.3746 - val_loss: 1.3983 - val_Accuracy: 0.3688\n",
      "Epoch 19/100\n",
      "375/375 [==============================] - 0s 1ms/step - loss: 1.3790 - Accuracy: 0.3842 - val_loss: 1.4037 - val_Accuracy: 0.3571\n",
      "Epoch 20/100\n",
      "375/375 [==============================] - 0s 1ms/step - loss: 1.3785 - Accuracy: 0.3778 - val_loss: 1.3984 - val_Accuracy: 0.3591\n",
      "Epoch 21/100\n",
      "375/375 [==============================] - 1s 1ms/step - loss: 1.3751 - Accuracy: 0.3795 - val_loss: 1.3972 - val_Accuracy: 0.3605\n",
      "Epoch 22/100\n",
      "375/375 [==============================] - 1s 1ms/step - loss: 1.3768 - Accuracy: 0.3781 - val_loss: 1.3993 - val_Accuracy: 0.3655\n",
      "Epoch 23/100\n",
      "375/375 [==============================] - 1s 1ms/step - loss: 1.3802 - Accuracy: 0.3780 - val_loss: 1.4028 - val_Accuracy: 0.3541\n",
      "Epoch 24/100\n",
      "375/375 [==============================] - 0s 1ms/step - loss: 1.3777 - Accuracy: 0.3829 - val_loss: 1.3997 - val_Accuracy: 0.3581\n",
      "Epoch 25/100\n",
      "375/375 [==============================] - 0s 1ms/step - loss: 1.3763 - Accuracy: 0.3765 - val_loss: 1.4034 - val_Accuracy: 0.3611\n",
      "Epoch 26/100\n",
      "375/375 [==============================] - 1s 1ms/step - loss: 1.3765 - Accuracy: 0.3824 - val_loss: 1.3957 - val_Accuracy: 0.3665\n",
      "Epoch 27/100\n",
      "375/375 [==============================] - 0s 1ms/step - loss: 1.3707 - Accuracy: 0.3823 - val_loss: 1.4081 - val_Accuracy: 0.3625\n",
      "Epoch 28/100\n",
      "375/375 [==============================] - 0s 1ms/step - loss: 1.3676 - Accuracy: 0.3861 - val_loss: 1.3984 - val_Accuracy: 0.3545\n",
      "Epoch 29/100\n",
      "375/375 [==============================] - 0s 1ms/step - loss: 1.3696 - Accuracy: 0.3842 - val_loss: 1.4059 - val_Accuracy: 0.3555\n",
      "Epoch 30/100\n",
      "375/375 [==============================] - 0s 1ms/step - loss: 1.3710 - Accuracy: 0.3807 - val_loss: 1.3962 - val_Accuracy: 0.3638\n",
      "Epoch 31/100\n",
      "375/375 [==============================] - 0s 1ms/step - loss: 1.3669 - Accuracy: 0.3858 - val_loss: 1.4008 - val_Accuracy: 0.3585\n",
      "Epoch 32/100\n",
      "375/375 [==============================] - 1s 1ms/step - loss: 1.3717 - Accuracy: 0.3857 - val_loss: 1.4049 - val_Accuracy: 0.3481\n",
      "Epoch 33/100\n",
      "375/375 [==============================] - 0s 1ms/step - loss: 1.3712 - Accuracy: 0.3848 - val_loss: 1.4055 - val_Accuracy: 0.3618\n",
      "Epoch 34/100\n",
      "375/375 [==============================] - 1s 1ms/step - loss: 1.3671 - Accuracy: 0.3860 - val_loss: 1.4036 - val_Accuracy: 0.3611\n",
      "Epoch 35/100\n",
      "375/375 [==============================] - 0s 1ms/step - loss: 1.3650 - Accuracy: 0.3844 - val_loss: 1.4010 - val_Accuracy: 0.3548\n",
      "Epoch 36/100\n",
      "375/375 [==============================] - 0s 1ms/step - loss: 1.3669 - Accuracy: 0.3830 - val_loss: 1.4047 - val_Accuracy: 0.3621\n",
      "Epoch 37/100\n",
      "375/375 [==============================] - 1s 1ms/step - loss: 1.3661 - Accuracy: 0.3862 - val_loss: 1.4036 - val_Accuracy: 0.3611\n",
      "Epoch 38/100\n",
      "375/375 [==============================] - 0s 1ms/step - loss: 1.3634 - Accuracy: 0.3854 - val_loss: 1.3948 - val_Accuracy: 0.3668\n",
      "Epoch 39/100\n",
      "375/375 [==============================] - 0s 1ms/step - loss: 1.3623 - Accuracy: 0.3870 - val_loss: 1.4123 - val_Accuracy: 0.3531\n",
      "Epoch 40/100\n",
      "375/375 [==============================] - 0s 1ms/step - loss: 1.3712 - Accuracy: 0.3818 - val_loss: 1.4080 - val_Accuracy: 0.3478\n",
      "Epoch 41/100\n",
      "375/375 [==============================] - 1s 1ms/step - loss: 1.3584 - Accuracy: 0.3911 - val_loss: 1.4016 - val_Accuracy: 0.3528\n",
      "Epoch 42/100\n",
      "375/375 [==============================] - 1s 1ms/step - loss: 1.3604 - Accuracy: 0.3858 - val_loss: 1.4182 - val_Accuracy: 0.3615\n",
      "Epoch 43/100\n",
      "375/375 [==============================] - 0s 1ms/step - loss: 1.3607 - Accuracy: 0.3891 - val_loss: 1.4113 - val_Accuracy: 0.3641\n",
      "Epoch 44/100\n",
      "375/375 [==============================] - 0s 1ms/step - loss: 1.3653 - Accuracy: 0.3883 - val_loss: 1.4039 - val_Accuracy: 0.3611\n",
      "Epoch 45/100\n",
      "375/375 [==============================] - 0s 1ms/step - loss: 1.3588 - Accuracy: 0.3917 - val_loss: 1.4017 - val_Accuracy: 0.3615\n",
      "Epoch 46/100\n",
      "375/375 [==============================] - 0s 1ms/step - loss: 1.3625 - Accuracy: 0.3898 - val_loss: 1.4014 - val_Accuracy: 0.3598\n",
      "Epoch 47/100\n",
      "375/375 [==============================] - 0s 1ms/step - loss: 1.3576 - Accuracy: 0.3935 - val_loss: 1.4056 - val_Accuracy: 0.3621\n",
      "Epoch 48/100\n",
      "375/375 [==============================] - 0s 1ms/step - loss: 1.3587 - Accuracy: 0.3924 - val_loss: 1.4089 - val_Accuracy: 0.3621\n",
      "Epoch 49/100\n",
      "375/375 [==============================] - 1s 1ms/step - loss: 1.3577 - Accuracy: 0.3895 - val_loss: 1.4208 - val_Accuracy: 0.3505\n",
      "Epoch 50/100\n",
      "375/375 [==============================] - 1s 1ms/step - loss: 1.3593 - Accuracy: 0.3891 - val_loss: 1.4353 - val_Accuracy: 0.3531\n",
      "Epoch 51/100\n",
      "375/375 [==============================] - 1s 1ms/step - loss: 1.3573 - Accuracy: 0.3871 - val_loss: 1.4046 - val_Accuracy: 0.3655\n",
      "Epoch 52/100\n",
      "375/375 [==============================] - 0s 1ms/step - loss: 1.3546 - Accuracy: 0.3923 - val_loss: 1.4163 - val_Accuracy: 0.3601\n",
      "Epoch 53/100\n",
      "375/375 [==============================] - 0s 1ms/step - loss: 1.3580 - Accuracy: 0.3909 - val_loss: 1.4218 - val_Accuracy: 0.3598\n",
      "Epoch 54/100\n",
      "375/375 [==============================] - 0s 1ms/step - loss: 1.3580 - Accuracy: 0.3902 - val_loss: 1.4002 - val_Accuracy: 0.3648\n",
      "Epoch 55/100\n",
      "375/375 [==============================] - 0s 1ms/step - loss: 1.3558 - Accuracy: 0.3864 - val_loss: 1.4031 - val_Accuracy: 0.3595\n",
      "Epoch 56/100\n",
      "375/375 [==============================] - 0s 1ms/step - loss: 1.3552 - Accuracy: 0.3916 - val_loss: 1.4062 - val_Accuracy: 0.3628\n",
      "Epoch 57/100\n",
      "375/375 [==============================] - 0s 1ms/step - loss: 1.3572 - Accuracy: 0.3916 - val_loss: 1.4084 - val_Accuracy: 0.3601\n",
      "Epoch 58/100\n",
      "375/375 [==============================] - 0s 1ms/step - loss: 1.3587 - Accuracy: 0.3943 - val_loss: 1.4063 - val_Accuracy: 0.3501\n",
      "Epoch 59/100\n",
      "375/375 [==============================] - 0s 1ms/step - loss: 1.3544 - Accuracy: 0.3945 - val_loss: 1.4074 - val_Accuracy: 0.3661\n",
      "Epoch 60/100\n",
      "375/375 [==============================] - 0s 1ms/step - loss: 1.3572 - Accuracy: 0.3902 - val_loss: 1.4107 - val_Accuracy: 0.3578\n",
      "Epoch 61/100\n",
      "375/375 [==============================] - 0s 1ms/step - loss: 1.3530 - Accuracy: 0.3861 - val_loss: 1.4084 - val_Accuracy: 0.3635\n",
      "Epoch 62/100\n",
      "375/375 [==============================] - 0s 1ms/step - loss: 1.3566 - Accuracy: 0.3895 - val_loss: 1.4210 - val_Accuracy: 0.3545\n",
      "Epoch 63/100\n",
      "375/375 [==============================] - 0s 1ms/step - loss: 1.3564 - Accuracy: 0.3905 - val_loss: 1.4011 - val_Accuracy: 0.3678\n",
      "Epoch 64/100\n",
      "375/375 [==============================] - 0s 1ms/step - loss: 1.3545 - Accuracy: 0.3855 - val_loss: 1.4197 - val_Accuracy: 0.3555\n",
      "Epoch 65/100\n",
      "375/375 [==============================] - 0s 1ms/step - loss: 1.3539 - Accuracy: 0.3901 - val_loss: 1.4028 - val_Accuracy: 0.3598\n",
      "Epoch 66/100\n",
      "375/375 [==============================] - 0s 1ms/step - loss: 1.3592 - Accuracy: 0.3870 - val_loss: 1.4139 - val_Accuracy: 0.3575\n",
      "Epoch 67/100\n",
      "375/375 [==============================] - 0s 1ms/step - loss: 1.3546 - Accuracy: 0.3914 - val_loss: 1.4230 - val_Accuracy: 0.3571\n",
      "Epoch 68/100\n",
      "375/375 [==============================] - 0s 1ms/step - loss: 1.3498 - Accuracy: 0.3924 - val_loss: 1.4163 - val_Accuracy: 0.3631\n",
      "Epoch 69/100\n",
      "375/375 [==============================] - 1s 1ms/step - loss: 1.3515 - Accuracy: 0.3914 - val_loss: 1.4046 - val_Accuracy: 0.3611\n",
      "Epoch 70/100\n",
      "375/375 [==============================] - 0s 1ms/step - loss: 1.3508 - Accuracy: 0.3893 - val_loss: 1.4044 - val_Accuracy: 0.3615\n",
      "Epoch 71/100\n",
      "375/375 [==============================] - 0s 1ms/step - loss: 1.3548 - Accuracy: 0.3873 - val_loss: 1.4053 - val_Accuracy: 0.3565\n",
      "Epoch 72/100\n",
      "375/375 [==============================] - 0s 1ms/step - loss: 1.3519 - Accuracy: 0.3940 - val_loss: 1.4049 - val_Accuracy: 0.3565\n",
      "Epoch 73/100\n",
      "375/375 [==============================] - 0s 1ms/step - loss: 1.3493 - Accuracy: 0.3914 - val_loss: 1.4009 - val_Accuracy: 0.3601\n",
      "Epoch 74/100\n",
      "375/375 [==============================] - 0s 1ms/step - loss: 1.3539 - Accuracy: 0.3914 - val_loss: 1.4167 - val_Accuracy: 0.3601\n",
      "Epoch 75/100\n",
      "375/375 [==============================] - 0s 1ms/step - loss: 1.3566 - Accuracy: 0.3865 - val_loss: 1.4114 - val_Accuracy: 0.3585\n",
      "Epoch 76/100\n",
      "375/375 [==============================] - 0s 1ms/step - loss: 1.3533 - Accuracy: 0.3923 - val_loss: 1.4143 - val_Accuracy: 0.3595\n",
      "Epoch 77/100\n",
      "375/375 [==============================] - 0s 1ms/step - loss: 1.3495 - Accuracy: 0.3919 - val_loss: 1.4126 - val_Accuracy: 0.3638\n",
      "Epoch 78/100\n",
      "375/375 [==============================] - 0s 1ms/step - loss: 1.3502 - Accuracy: 0.3914 - val_loss: 1.4126 - val_Accuracy: 0.3568\n",
      "Epoch 79/100\n",
      "375/375 [==============================] - 0s 1ms/step - loss: 1.3493 - Accuracy: 0.3929 - val_loss: 1.4151 - val_Accuracy: 0.3565\n",
      "Epoch 80/100\n",
      "375/375 [==============================] - 0s 1ms/step - loss: 1.3519 - Accuracy: 0.3891 - val_loss: 1.4179 - val_Accuracy: 0.3621\n",
      "Epoch 81/100\n",
      "375/375 [==============================] - 0s 1ms/step - loss: 1.3505 - Accuracy: 0.3934 - val_loss: 1.4079 - val_Accuracy: 0.3638\n",
      "Epoch 82/100\n",
      "375/375 [==============================] - 0s 1ms/step - loss: 1.3508 - Accuracy: 0.3906 - val_loss: 1.4258 - val_Accuracy: 0.3611\n",
      "Epoch 83/100\n",
      "375/375 [==============================] - 0s 1ms/step - loss: 1.3503 - Accuracy: 0.3879 - val_loss: 1.4107 - val_Accuracy: 0.3575\n",
      "Epoch 84/100\n",
      "375/375 [==============================] - 0s 1ms/step - loss: 1.3475 - Accuracy: 0.3914 - val_loss: 1.4056 - val_Accuracy: 0.3641\n",
      "Epoch 85/100\n",
      "375/375 [==============================] - 0s 1ms/step - loss: 1.3504 - Accuracy: 0.3895 - val_loss: 1.4225 - val_Accuracy: 0.3631\n",
      "Epoch 86/100\n",
      "375/375 [==============================] - 0s 1ms/step - loss: 1.3520 - Accuracy: 0.3909 - val_loss: 1.4113 - val_Accuracy: 0.3548\n",
      "Epoch 87/100\n",
      "375/375 [==============================] - 0s 1ms/step - loss: 1.3482 - Accuracy: 0.3908 - val_loss: 1.4211 - val_Accuracy: 0.3501\n",
      "Epoch 88/100\n",
      "375/375 [==============================] - 0s 1ms/step - loss: 1.3487 - Accuracy: 0.3895 - val_loss: 1.4161 - val_Accuracy: 0.3474\n",
      "Epoch 89/100\n",
      "375/375 [==============================] - 0s 1ms/step - loss: 1.3464 - Accuracy: 0.3889 - val_loss: 1.4286 - val_Accuracy: 0.3631\n",
      "Epoch 90/100\n",
      "375/375 [==============================] - 0s 1ms/step - loss: 1.3491 - Accuracy: 0.3907 - val_loss: 1.4094 - val_Accuracy: 0.3585\n",
      "Epoch 91/100\n",
      "375/375 [==============================] - 0s 1ms/step - loss: 1.3515 - Accuracy: 0.3894 - val_loss: 1.4157 - val_Accuracy: 0.3598\n",
      "Epoch 92/100\n",
      "375/375 [==============================] - 0s 1ms/step - loss: 1.3473 - Accuracy: 0.3903 - val_loss: 1.4169 - val_Accuracy: 0.3615\n",
      "Epoch 93/100\n",
      "375/375 [==============================] - 0s 1ms/step - loss: 1.3468 - Accuracy: 0.3899 - val_loss: 1.4232 - val_Accuracy: 0.3555\n",
      "Epoch 94/100\n",
      "375/375 [==============================] - 0s 1ms/step - loss: 1.3476 - Accuracy: 0.3884 - val_loss: 1.4144 - val_Accuracy: 0.3635\n",
      "Epoch 95/100\n",
      "375/375 [==============================] - 0s 1ms/step - loss: 1.3483 - Accuracy: 0.3924 - val_loss: 1.4129 - val_Accuracy: 0.3588\n",
      "Epoch 96/100\n",
      "375/375 [==============================] - 0s 1ms/step - loss: 1.3466 - Accuracy: 0.3912 - val_loss: 1.4112 - val_Accuracy: 0.3645\n",
      "Epoch 97/100\n",
      "375/375 [==============================] - 0s 1ms/step - loss: 1.3492 - Accuracy: 0.3907 - val_loss: 1.4239 - val_Accuracy: 0.3581\n",
      "Epoch 98/100\n",
      "375/375 [==============================] - 0s 1ms/step - loss: 1.3510 - Accuracy: 0.3889 - val_loss: 1.4244 - val_Accuracy: 0.3575\n",
      "Epoch 99/100\n",
      "375/375 [==============================] - 0s 1ms/step - loss: 1.3487 - Accuracy: 0.3902 - val_loss: 1.4169 - val_Accuracy: 0.3638\n",
      "Epoch 100/100\n",
      "375/375 [==============================] - 0s 1ms/step - loss: 1.3458 - Accuracy: 0.3910 - val_loss: 1.4211 - val_Accuracy: 0.3585\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x187e8bee710>"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(\n",
    "    data_train,\n",
    "    label_train,\n",
    "    epochs=100,\n",
    "    validation_data=(data_eval,label_eval)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Predicting using categorical, numerical and text data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 Importing necessary libs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenizer and sequence padding\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "# tf keras function to build model\n",
    "from tensorflow.keras.layers import Input, LSTM, Dense, Embedding, Concatenate\n",
    "from tensorflow.keras.models import Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 Preprocessing text and numerical-categorical data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### TOKENIZING ON TEXT DATA ####\n",
    "# tokenize base on 'description' column in train data\n",
    "train['Description'].fillna('', inplace=True)     # Handle missing values by filling NaN with an empty string\n",
    "train['Description'] = train['Description'].str.lower()    # Convert descriptions to lowercase\n",
    "tokenizer = Tokenizer() # Start tokenizing\n",
    "tokenizer.fit_on_texts(train['Description'])\n",
    "# get word index\n",
    "word_index = tokenizer.word_index\n",
    "max_word_index = max(word_index.values()) # 21808"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#### CONVERTING TEXT TO INDEXES AND TO SEQUENCES ####\n",
    "# convert indexes to sequences\n",
    "train['Description'] = train['Description'].astype(str) # astype of column to string \n",
    "seq = tokenizer.texts_to_sequences(train['Description'])\n",
    "# length of each sentence in 'description' column\n",
    "length_dist = [len(seq_i) for seq_i in seq]\n",
    "sns.kdeplot(length_dist) # most of them center around 200-400, lets set maxlen to 200\n",
    "# padding sequences\n",
    "padded_train_eval = pad_sequences(seq, maxlen = 200,truncating='post', padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### ONE-HOT CODING, EXTRACTING LABEL FROM ORIGINAL NON-TEXT DATA #####\n",
    "train_eval = get_input(train,breed,color,state)[0] # use get_input function previously defined\n",
    "# get label data\n",
    "y_list = ['AdoptionSpeed_First_day', 'AdoptionSpeed_First_week', 'AdoptionSpeed_First_month', 'AdoptionSpeed_First_30_to_90_days', 'AdoptionSpeed_First_100_days']\n",
    "label_train_eval = train_eval[y_list]\n",
    "# drop y_column to get input data\n",
    "data_train_eval = train_eval.drop(y_list,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### CONCATINATING TEXT AND NON TEXT DATA #####\n",
    "full_concated_data = np.concatenate((data_train_eval, padded_train_eval), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11994, 567) (11994, 5) (2999, 567) (2999, 5)\n"
     ]
    }
   ],
   "source": [
    "##### SPLITING INTO TRAIN-EVALUATION DATA SET #####\n",
    "n_split = math.floor(full_concated_data.shape[0] * 0.8)\n",
    "# Split data\n",
    "data_train = full_concated_data[:n_split,:]\n",
    "data_eval = full_concated_data[n_split:,:]\n",
    "# Split label\n",
    "label_train = label_train_eval.iloc[:n_split,:].values\n",
    "label_eval = label_train_eval.iloc[n_split:,:].values\n",
    "# Printing shape of these data sets\n",
    "print(\n",
    "    data_train.shape,\n",
    "    label_train.shape,\n",
    "    data_eval.shape,\n",
    "    label_eval.shape\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3 Model building and evaluating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function that get model\n",
    "def get_model(input_data, text_dimension):\n",
    "    total_dimension = input_data.shape[1]\n",
    "    textinput_dimension = text_dimension\n",
    "    # Spliting input numerical and text data\n",
    "    input_layer = Input(shape=(total_dimension,))\n",
    "    numin, textin = tf.split(input_layer, num_or_size_splits=[total_dimension - textinput_dimension, textinput_dimension], axis=1)\n",
    "    # Model for numerical data\n",
    "    Dense1 = Dense(200)(numin)\n",
    "    Dense2 = Dense(150)(Dense1)\n",
    "    Dense3 = Dense(100)(Dense2)\n",
    "    Dense4 = Dense(50)(Dense3)\n",
    "    # Model for text data\n",
    "    em = Embedding(max_word_index + 1, 100, input_length = textinput_dimension)(textin) # Current dimension = max_word_index + 1\n",
    "    lstm = LSTM(textinput_dimension)(em) \n",
    "    Dense5 = Dense(50)(lstm)\n",
    "    Dense6 = Dense(20)(Dense5)\n",
    "    # Concatenate value from two previous paths\n",
    "    merged = Concatenate()([Dense4, Dense6])\n",
    "    # Last layer would be softmax\n",
    "    output = Dense(5, activation='softmax')(merged)\n",
    "    # Generate model\n",
    "    model = Model(inputs=input_layer, outputs=output)\n",
    "    # Compiling model\n",
    "    model.compile(optimizer='adam', loss=tf.keras.losses.CategoricalCrossentropy(), metrics=['accuracy'])\n",
    "    # Createing a checkpoint path to automatically save model\n",
    "    checkpoint_path = os.path.join(os.getcwd(), \"num_text_models\\cp.ckpt\")\n",
    "    checkpoint_dir = os.path.dirname(checkpoint_path)\n",
    "    # Create a callback that saves the model's weights\n",
    "    cp_callback = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_path,\n",
    "                                                    save_weights_only=True\n",
    "                                                    )\n",
    "    return model, cp_callback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "model, cp_callback = get_model(data_train, 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 0.6372 - recall: 0.7074 - val_loss: 0.6477 - val_recall: 0.6818\n",
      "Epoch 2/10\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.6351 - recall: 0.6773 - val_loss: 0.6489 - val_recall: 0.6584\n",
      "Epoch 3/10\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.6347 - recall: 0.6620 - val_loss: 0.6488 - val_recall: 0.6474\n",
      "Epoch 4/10\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.6347 - recall: 0.6543 - val_loss: 0.6497 - val_recall: 0.6591\n",
      "Epoch 5/10\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.6346 - recall: 0.6665 - val_loss: 0.6501 - val_recall: 0.6578\n",
      "Epoch 6/10\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.6346 - recall: 0.6512 - val_loss: 0.6496 - val_recall: 0.6532\n",
      "Epoch 7/10\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.6346 - recall: 0.6610 - val_loss: 0.6498 - val_recall: 0.6442\n",
      "Epoch 8/10\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.6345 - recall: 0.6567 - val_loss: 0.6497 - val_recall: 0.6500\n",
      "Epoch 9/10\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.6343 - recall: 0.6682 - val_loss: 0.6497 - val_recall: 0.6500\n",
      "Epoch 10/10\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.6346 - recall: 0.6635 - val_loss: 0.6493 - val_recall: 0.6474\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x1882ef3f890>"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(\n",
    "    x= data_train, \n",
    "    y= label_train, \n",
    "    epochs= 10, \n",
    "    batch_size = 2**9, \n",
    "    validation_data = (data_eval,label_eval),\n",
    "    callbacks= [cp_callback]\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Try changing target variable format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['AdoptionSpeed'] = train['AdoptionSpeed'].astype(int).apply(lambda x: \n",
    "                                                1 if x <= 2\n",
    "                                                else 0\n",
    "                                                ) # 1 =  Fast (<1 moth), 0 = Slow (>=1 month)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "########  DEFINING A FUNCTION THAT PREPARE CORRECT INPUT FOR MODEL #########\n",
    "def get_input_new(df, breed,color,state):\n",
    "    # Merging with other tables to get labels\n",
    "    df_drop = df.drop(['PhotoAmt','PetID','Description','VideoAmt','RescuerID','Name'],axis=1)\n",
    "    df_drop = df_drop.rename(columns={'Breed1':'BreedID'}).merge(breed, on=['BreedID','Type'],how='left').drop('BreedID',axis=1)\n",
    "    df_drop = df_drop.rename(columns={'Breed2':'BreedID'}).merge(breed, on=['BreedID','Type'],how='left').drop('BreedID',axis=1)\n",
    "    \n",
    "    for color_col in ['Color1','Color2','Color3']:\n",
    "        df_drop = df_drop.rename(columns={color_col: 'ColorID'}).merge(color, on ='ColorID', how = 'left').drop('ColorID',axis=1)\n",
    "    df_drop = df_drop.rename(columns={'State':'StateID'}).merge(state,on ='StateID', how = 'left').drop('StateID',axis=1)\n",
    "\n",
    "    # Get label of data to understand the context\n",
    "    label_dict = {\n",
    "        'Type': ['Not specified','Dog','Cat'],\n",
    "        'Gender': ['Not specified','Male','Female','Mixed'],\n",
    "        'FurLength': ['Not specified','Short','Medium','Long'],\n",
    "        'Vaccinated': ['Not specified','Yes','No'],\n",
    "        'Dewormed': ['Not specified','Yes','No'],\n",
    "        'Sterilized': ['Not specified','Yes','No'],\n",
    "        'Health': ['Not specified','Healthy','Minor Injury','Serious Injury'],\n",
    "        'MaturitySize': ['Not specified','Small','Medium','Large','Extra Large']\n",
    "    }\n",
    "\n",
    "    for col in df_drop.columns:\n",
    "        if col in label_dict:\n",
    "            label_list = label_dict[col]\n",
    "            for number in range(len(label_list)):\n",
    "                df_drop[col][df_drop[col] == number] = label_list[number]\n",
    "    df_labeled = df_drop\n",
    "    df_dummy = pd.get_dummies(df_labeled,dtype=int)\n",
    "    \n",
    "    return df_dummy, df_labeled"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11994, 367) (11994, 1) (2999, 367) (2999, 1)\n"
     ]
    }
   ],
   "source": [
    "# get desired input\n",
    "data_train_eval = get_input_new(train, breed, color, state)[0] # take df_dum\n",
    "label_train_eval = data_train_eval[['AdoptionSpeed']]\n",
    "data_train_eval = data_train_eval.drop('AdoptionSpeed', axis = 1)\n",
    "\n",
    "# Split train data to train - evaluate set:\n",
    "n_split = math.floor(data_train_eval.shape[0] * 0.8)\n",
    "\n",
    "data_train = data_train_eval.iloc[:n_split,:]\n",
    "data_eval = data_train_eval.iloc[n_split:,:]\n",
    "\n",
    "label_train = label_train_eval.iloc[:n_split,:]\n",
    "label_eval = label_train_eval.iloc[n_split:,:]\n",
    "\n",
    "# print out shape\n",
    "print(\n",
    "    data_train.shape,\n",
    "    label_train.shape,\n",
    "    data_eval.shape,\n",
    "    label_eval.shape \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.8392 - recall: 0.6405 - val_loss: 0.6653 - val_recall: 0.5552\n",
      "Epoch 2/100\n",
      "375/375 [==============================] - 0s 1ms/step - loss: 0.6918 - recall: 0.6392 - val_loss: 0.6872 - val_recall: 0.7078\n",
      "Epoch 3/100\n",
      "375/375 [==============================] - 0s 1ms/step - loss: 0.6711 - recall: 0.6308 - val_loss: 0.6651 - val_recall: 0.7558\n",
      "Epoch 4/100\n",
      "375/375 [==============================] - 0s 1ms/step - loss: 0.6795 - recall: 0.6627 - val_loss: 0.6759 - val_recall: 0.5058\n",
      "Epoch 5/100\n",
      "375/375 [==============================] - 0s 1ms/step - loss: 0.6554 - recall: 0.6455 - val_loss: 0.6719 - val_recall: 0.7799\n",
      "Epoch 6/100\n",
      "375/375 [==============================] - 0s 1ms/step - loss: 0.6772 - recall: 0.6490 - val_loss: 0.6537 - val_recall: 0.6026\n",
      "Epoch 7/100\n",
      "375/375 [==============================] - 0s 1ms/step - loss: 0.6680 - recall: 0.6695 - val_loss: 0.6518 - val_recall: 0.6552\n",
      "Epoch 8/100\n",
      "375/375 [==============================] - 0s 1ms/step - loss: 0.6650 - recall: 0.6530 - val_loss: 0.6641 - val_recall: 0.6870\n",
      "Epoch 9/100\n",
      "375/375 [==============================] - 0s 1ms/step - loss: 0.6505 - recall: 0.6412 - val_loss: 0.6598 - val_recall: 0.6669\n",
      "Epoch 10/100\n",
      "375/375 [==============================] - 0s 1ms/step - loss: 0.6544 - recall: 0.6643 - val_loss: 0.6544 - val_recall: 0.6091\n",
      "Epoch 11/100\n",
      "375/375 [==============================] - 0s 1ms/step - loss: 0.6529 - recall: 0.6518 - val_loss: 0.6500 - val_recall: 0.6838\n",
      "Epoch 12/100\n",
      "375/375 [==============================] - 0s 1ms/step - loss: 0.6489 - recall: 0.6478 - val_loss: 0.6581 - val_recall: 0.5234\n",
      "Epoch 13/100\n",
      "375/375 [==============================] - 0s 1ms/step - loss: 0.6495 - recall: 0.6448 - val_loss: 0.6488 - val_recall: 0.6714\n",
      "Epoch 14/100\n",
      "375/375 [==============================] - 0s 1ms/step - loss: 0.6506 - recall: 0.6542 - val_loss: 0.6527 - val_recall: 0.6039\n",
      "Epoch 15/100\n",
      "375/375 [==============================] - 0s 1ms/step - loss: 0.6476 - recall: 0.6533 - val_loss: 0.6481 - val_recall: 0.6565\n",
      "Epoch 16/100\n",
      "375/375 [==============================] - 1s 1ms/step - loss: 0.6471 - recall: 0.6450 - val_loss: 0.6839 - val_recall: 0.6968\n",
      "Epoch 17/100\n",
      "375/375 [==============================] - 0s 1ms/step - loss: 0.6479 - recall: 0.6630 - val_loss: 0.6509 - val_recall: 0.6909\n",
      "Epoch 18/100\n",
      "375/375 [==============================] - 0s 1ms/step - loss: 0.6455 - recall: 0.6502 - val_loss: 0.6503 - val_recall: 0.6266\n",
      "Epoch 19/100\n",
      "375/375 [==============================] - 0s 1ms/step - loss: 0.6453 - recall: 0.6483 - val_loss: 0.6565 - val_recall: 0.6662\n",
      "Epoch 20/100\n",
      "375/375 [==============================] - 0s 1ms/step - loss: 0.6456 - recall: 0.6528 - val_loss: 0.6470 - val_recall: 0.6974\n",
      "Epoch 21/100\n",
      "375/375 [==============================] - 0s 1ms/step - loss: 0.6453 - recall: 0.6515 - val_loss: 0.6515 - val_recall: 0.6318\n",
      "Epoch 22/100\n",
      "375/375 [==============================] - 1s 1ms/step - loss: 0.6441 - recall: 0.6527 - val_loss: 0.6505 - val_recall: 0.6149\n",
      "Epoch 23/100\n",
      "375/375 [==============================] - 0s 1ms/step - loss: 0.6450 - recall: 0.6598 - val_loss: 0.6502 - val_recall: 0.6584\n",
      "Epoch 24/100\n",
      "375/375 [==============================] - 0s 1ms/step - loss: 0.6452 - recall: 0.6462 - val_loss: 0.6469 - val_recall: 0.6487\n",
      "Epoch 25/100\n",
      "375/375 [==============================] - 0s 1ms/step - loss: 0.6487 - recall: 0.6492 - val_loss: 0.6482 - val_recall: 0.7182\n",
      "Epoch 26/100\n",
      "375/375 [==============================] - 1s 1ms/step - loss: 0.6491 - recall: 0.6532 - val_loss: 0.6568 - val_recall: 0.6870\n",
      "Epoch 27/100\n",
      "375/375 [==============================] - 0s 1ms/step - loss: 0.6429 - recall: 0.6578 - val_loss: 0.6511 - val_recall: 0.6065\n",
      "Epoch 28/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.6430 - recall: 0.6513 - val_loss: 0.6485 - val_recall: 0.6669\n",
      "Epoch 29/100\n",
      "375/375 [==============================] - 1s 1ms/step - loss: 0.6424 - recall: 0.6495 - val_loss: 0.6486 - val_recall: 0.6643\n",
      "Epoch 30/100\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.6432 - recall: 0.6533 - val_loss: 0.6484 - val_recall: 0.6747\n",
      "Epoch 31/100\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.6435 - recall: 0.6620 - val_loss: 0.6590 - val_recall: 0.6468\n",
      "Epoch 32/100\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.6415 - recall: 0.6620 - val_loss: 0.6498 - val_recall: 0.5890\n",
      "Epoch 33/100\n",
      "375/375 [==============================] - 1s 1ms/step - loss: 0.6417 - recall: 0.6525 - val_loss: 0.6486 - val_recall: 0.6390\n",
      "Epoch 34/100\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.6427 - recall: 0.6548 - val_loss: 0.6472 - val_recall: 0.6422\n",
      "Epoch 35/100\n",
      "375/375 [==============================] - 1s 1ms/step - loss: 0.6421 - recall: 0.6613 - val_loss: 0.6708 - val_recall: 0.5864\n",
      "Epoch 36/100\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.6440 - recall: 0.6552 - val_loss: 0.6540 - val_recall: 0.5714\n",
      "Epoch 37/100\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.6416 - recall: 0.6527 - val_loss: 0.6511 - val_recall: 0.6636\n",
      "Epoch 38/100\n",
      "375/375 [==============================] - 1s 1ms/step - loss: 0.6416 - recall: 0.6567 - val_loss: 0.6479 - val_recall: 0.6695\n",
      "Epoch 39/100\n",
      "375/375 [==============================] - 1s 1ms/step - loss: 0.6392 - recall: 0.6582 - val_loss: 0.6731 - val_recall: 0.7084\n",
      "Epoch 40/100\n",
      "375/375 [==============================] - 1s 1ms/step - loss: 0.6406 - recall: 0.6602 - val_loss: 0.6482 - val_recall: 0.6578\n",
      "Epoch 41/100\n",
      "375/375 [==============================] - 1s 1ms/step - loss: 0.6407 - recall: 0.6628 - val_loss: 0.6584 - val_recall: 0.6714\n",
      "Epoch 42/100\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.6412 - recall: 0.6560 - val_loss: 0.6484 - val_recall: 0.6727\n",
      "Epoch 43/100\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.6417 - recall: 0.6660 - val_loss: 0.6481 - val_recall: 0.6214\n",
      "Epoch 44/100\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.6393 - recall: 0.6438 - val_loss: 0.6591 - val_recall: 0.7701\n",
      "Epoch 45/100\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.6417 - recall: 0.6653 - val_loss: 0.6509 - val_recall: 0.5760\n",
      "Epoch 46/100\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.6390 - recall: 0.6513 - val_loss: 0.6510 - val_recall: 0.6675\n",
      "Epoch 47/100\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.6426 - recall: 0.6575 - val_loss: 0.6554 - val_recall: 0.6935\n",
      "Epoch 48/100\n",
      "120/375 [========>.....................] - ETA: 0s - loss: 0.6407 - recall: 0.6595"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Admin\\PetAdoption\\PetAdoption_code.ipynb Cell 40\u001b[0m line \u001b[0;36m1\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Admin/PetAdoption/PetAdoption_code.ipynb#X55sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m model \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mkeras\u001b[39m.\u001b[39mSequential([\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Admin/PetAdoption/PetAdoption_code.ipynb#X55sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m     tf\u001b[39m.\u001b[39mkeras\u001b[39m.\u001b[39mInput(shape\u001b[39m=\u001b[39m(data_train\u001b[39m.\u001b[39mshape[\u001b[39m1\u001b[39m],)),\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Admin/PetAdoption/PetAdoption_code.ipynb#X55sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m     tf\u001b[39m.\u001b[39mkeras\u001b[39m.\u001b[39mlayers\u001b[39m.\u001b[39mDense(units\u001b[39m=\u001b[39m\u001b[39m200\u001b[39m),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Admin/PetAdoption/PetAdoption_code.ipynb#X55sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m     tf\u001b[39m.\u001b[39mkeras\u001b[39m.\u001b[39mlayers\u001b[39m.\u001b[39mDense(units\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m, activation\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39msigmoid\u001b[39m\u001b[39m'\u001b[39m),\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Admin/PetAdoption/PetAdoption_code.ipynb#X55sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m ])\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Admin/PetAdoption/PetAdoption_code.ipynb#X55sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m model\u001b[39m.\u001b[39mcompile(\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Admin/PetAdoption/PetAdoption_code.ipynb#X55sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m     loss\u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mBinaryCrossentropy\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Admin/PetAdoption/PetAdoption_code.ipynb#X55sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m     optimizer\u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mAdam\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Admin/PetAdoption/PetAdoption_code.ipynb#X55sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m     metrics \u001b[39m=\u001b[39m [\u001b[39m'\u001b[39m\u001b[39mRecall\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Admin/PetAdoption/PetAdoption_code.ipynb#X55sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m )\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/Admin/PetAdoption/PetAdoption_code.ipynb#X55sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m model\u001b[39m.\u001b[39;49mfit(\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Admin/PetAdoption/PetAdoption_code.ipynb#X55sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m     data_train,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Admin/PetAdoption/PetAdoption_code.ipynb#X55sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m     label_train,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Admin/PetAdoption/PetAdoption_code.ipynb#X55sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m     epochs \u001b[39m=\u001b[39;49m \u001b[39m100\u001b[39;49m,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Admin/PetAdoption/PetAdoption_code.ipynb#X55sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m     validation_data\u001b[39m=\u001b[39;49m(data_eval, label_eval)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Admin/PetAdoption/PetAdoption_code.ipynb#X55sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m     66\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\training.py:1742\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1734\u001b[0m \u001b[39mwith\u001b[39;00m tf\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mexperimental\u001b[39m.\u001b[39mTrace(\n\u001b[0;32m   1735\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m   1736\u001b[0m     epoch_num\u001b[39m=\u001b[39mepoch,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1739\u001b[0m     _r\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m,\n\u001b[0;32m   1740\u001b[0m ):\n\u001b[0;32m   1741\u001b[0m     callbacks\u001b[39m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m-> 1742\u001b[0m     tmp_logs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain_function(iterator)\n\u001b[0;32m   1743\u001b[0m     \u001b[39mif\u001b[39;00m data_handler\u001b[39m.\u001b[39mshould_sync:\n\u001b[0;32m   1744\u001b[0m         context\u001b[39m.\u001b[39masync_wait()\n",
      "File \u001b[1;32mc:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:825\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    822\u001b[0m compiler \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mxla\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mnonXla\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    824\u001b[0m \u001b[39mwith\u001b[39;00m OptionalXlaContext(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 825\u001b[0m   result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[0;32m    827\u001b[0m new_tracing_count \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    828\u001b[0m without_tracing \u001b[39m=\u001b[39m (tracing_count \u001b[39m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32mc:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:857\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    854\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n\u001b[0;32m    855\u001b[0m   \u001b[39m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[0;32m    856\u001b[0m   \u001b[39m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[1;32m--> 857\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_no_variable_creation_fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)  \u001b[39m# pylint: disable=not-callable\u001b[39;00m\n\u001b[0;32m    858\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_variable_creation_fn \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    859\u001b[0m   \u001b[39m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[0;32m    860\u001b[0m   \u001b[39m# in parallel.\u001b[39;00m\n\u001b[0;32m    861\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n",
      "File \u001b[1;32mc:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compiler.py:148\u001b[0m, in \u001b[0;36mTracingCompiler.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    145\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[0;32m    146\u001b[0m   (concrete_function,\n\u001b[0;32m    147\u001b[0m    filtered_flat_args) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[1;32m--> 148\u001b[0m \u001b[39mreturn\u001b[39;00m concrete_function\u001b[39m.\u001b[39;49m_call_flat(\n\u001b[0;32m    149\u001b[0m     filtered_flat_args, captured_inputs\u001b[39m=\u001b[39;49mconcrete_function\u001b[39m.\u001b[39;49mcaptured_inputs)\n",
      "File \u001b[1;32mc:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\monomorphic_function.py:1349\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, args, captured_inputs)\u001b[0m\n\u001b[0;32m   1345\u001b[0m possible_gradient_type \u001b[39m=\u001b[39m gradients_util\u001b[39m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1346\u001b[0m \u001b[39mif\u001b[39;00m (possible_gradient_type \u001b[39m==\u001b[39m gradients_util\u001b[39m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1347\u001b[0m     \u001b[39mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1348\u001b[0m   \u001b[39m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1349\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_build_call_outputs(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_inference_function(\u001b[39m*\u001b[39;49margs))\n\u001b[0;32m   1350\u001b[0m forward_backward \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1351\u001b[0m     args,\n\u001b[0;32m   1352\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1353\u001b[0m     executing_eagerly)\n\u001b[0;32m   1354\u001b[0m forward_function, args_with_tangents \u001b[39m=\u001b[39m forward_backward\u001b[39m.\u001b[39mforward()\n",
      "File \u001b[1;32mc:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:196\u001b[0m, in \u001b[0;36mAtomicFunction.__call__\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m    194\u001b[0m \u001b[39mwith\u001b[39;00m record\u001b[39m.\u001b[39mstop_recording():\n\u001b[0;32m    195\u001b[0m   \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_bound_context\u001b[39m.\u001b[39mexecuting_eagerly():\n\u001b[1;32m--> 196\u001b[0m     outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_bound_context\u001b[39m.\u001b[39;49mcall_function(\n\u001b[0;32m    197\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mname,\n\u001b[0;32m    198\u001b[0m         \u001b[39mlist\u001b[39;49m(args),\n\u001b[0;32m    199\u001b[0m         \u001b[39mlen\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfunction_type\u001b[39m.\u001b[39;49mflat_outputs),\n\u001b[0;32m    200\u001b[0m     )\n\u001b[0;32m    201\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    202\u001b[0m     outputs \u001b[39m=\u001b[39m make_call_op_in_graph(\u001b[39mself\u001b[39m, \u001b[39mlist\u001b[39m(args))\n",
      "File \u001b[1;32mc:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\eager\\context.py:1457\u001b[0m, in \u001b[0;36mContext.call_function\u001b[1;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[0;32m   1455\u001b[0m cancellation_context \u001b[39m=\u001b[39m cancellation\u001b[39m.\u001b[39mcontext()\n\u001b[0;32m   1456\u001b[0m \u001b[39mif\u001b[39;00m cancellation_context \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m-> 1457\u001b[0m   outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39;49mexecute(\n\u001b[0;32m   1458\u001b[0m       name\u001b[39m.\u001b[39;49mdecode(\u001b[39m\"\u001b[39;49m\u001b[39mutf-8\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[0;32m   1459\u001b[0m       num_outputs\u001b[39m=\u001b[39;49mnum_outputs,\n\u001b[0;32m   1460\u001b[0m       inputs\u001b[39m=\u001b[39;49mtensor_inputs,\n\u001b[0;32m   1461\u001b[0m       attrs\u001b[39m=\u001b[39;49mattrs,\n\u001b[0;32m   1462\u001b[0m       ctx\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m,\n\u001b[0;32m   1463\u001b[0m   )\n\u001b[0;32m   1464\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   1465\u001b[0m   outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m   1466\u001b[0m       name\u001b[39m.\u001b[39mdecode(\u001b[39m\"\u001b[39m\u001b[39mutf-8\u001b[39m\u001b[39m\"\u001b[39m),\n\u001b[0;32m   1467\u001b[0m       num_outputs\u001b[39m=\u001b[39mnum_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1471\u001b[0m       cancellation_manager\u001b[39m=\u001b[39mcancellation_context,\n\u001b[0;32m   1472\u001b[0m   )\n",
      "File \u001b[1;32mc:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\eager\\execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m     52\u001b[0m   ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 53\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39;49mTFE_Py_Execute(ctx\u001b[39m.\u001b[39;49m_handle, device_name, op_name,\n\u001b[0;32m     54\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[0;32m     55\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     56\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    tf.keras.Input(shape=(data_train.shape[1],)),\n",
    "    tf.keras.layers.Dense(units=200),\n",
    "    tf.keras.layers.Dense(units=150),\n",
    "    tf.keras.layers.Dense(units=100),\n",
    "    tf.keras.layers.Dense(units=50),\n",
    "    tf.keras.layers.Dense(units=1, activation='sigmoid'),\n",
    "])\n",
    "\n",
    "model.compile(\n",
    "    loss= 'BinaryCrossentropy',\n",
    "    optimizer= 'Adam',\n",
    "    metrics = ['Recall']\n",
    ")\n",
    "\n",
    "model.fit(\n",
    "    data_train,\n",
    "    label_train,\n",
    "    epochs = 100,\n",
    "    validation_data=(data_eval, label_eval)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def labeling_evaluating(y_true, y_pred, threshold):\n",
    "    y_pred[y_pred > threshold] = 1\n",
    "    y_pred[y_pred <= threshold] = 0\n",
    "\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    print(cm)\n",
    "\n",
    "    # visualizing confusion matrix:\n",
    "    sns.heatmap(cm, annot=True, cmap=\"crest\", fmt='.4g')\n",
    "\n",
    "    # calcualte metric dict \n",
    "    metric_dict = calculate_perform_metrics(cm)\n",
    "    print(metric_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labeling_evaluating(label_eval, \n",
    "                    model.predict(data_eval), \n",
    "                    threshold = 0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural network and RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### TOKENIZING ON TEXT DATA ####\n",
    "# tokenize base on 'description' column in train data\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(train['Description'].astype(str))\n",
    "# get word index\n",
    "word_index = tokenizer.word_index\n",
    "max_word_index = max(word_index.values()) # 21808\n",
    "\n",
    "#### CONVERTING TEXT TO INDEXES AND TO SEQUENCES ####\n",
    "# convert indexes to sequences\n",
    "train['Description'] = train['Description'].astype(str) # astype of column to string \n",
    "seq = tokenizer.texts_to_sequences(train['Description'])\n",
    "# length of each sentence in 'description' column\n",
    "length_dist = [len(seq_i) for seq_i in seq]\n",
    "sns.kdeplot(length_dist) # most of them center around 200-400, lets set maxlen to 200\n",
    "# padding sequences\n",
    "padded_train_eval = pad_sequences(seq, maxlen = 200,truncating='post', padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get desired input\n",
    "data_train_eval = get_input_new(train, breed, color, state)[0] # take df_dum\n",
    "label_train_eval = data_train_eval[['AdoptionSpeed']]\n",
    "data_train_eval = data_train_eval.drop('AdoptionSpeed', axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### CONCATINATING TEXT AND NON TEXT DATA #####\n",
    "full_concated_data = np.concatenate((data_train_eval, padded_train_eval), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### SPLITING INTO TRAIN-EVALUATION DATA SET #####\n",
    "n_split = math.floor(full_concated_data.shape[0] * 0.8)\n",
    "# Split data\n",
    "data_train = full_concated_data[:n_split,:]\n",
    "data_eval = full_concated_data[n_split:,:]\n",
    "# Split label\n",
    "label_train = label_train_eval.iloc[:n_split,:].values\n",
    "label_eval = label_train_eval.iloc[n_split:,:].values\n",
    "# Printing shape of these data sets\n",
    "print(\n",
    "    data_train.shape,\n",
    "    label_train.shape,\n",
    "    data_eval.shape,\n",
    "    label_eval.shape\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function that get model\n",
    "def get_model(input_data, text_dimension):\n",
    "    total_dimension = input_data.shape[1]\n",
    "    textinput_dimension = text_dimension\n",
    "    # Spliting input numerical and text data\n",
    "    input_layer = Input(shape=(total_dimension,))\n",
    "    numin, textin = tf.split(input_layer, num_or_size_splits=[total_dimension - textinput_dimension, textinput_dimension], axis=1)\n",
    "    # Model for numerical data\n",
    "    Dense1 = Dense(200)(numin)\n",
    "    Dense2 = Dense(150)(Dense1)\n",
    "    Dense3 = Dense(100)(Dense2)\n",
    "    Dense4 = Dense(50)(Dense3)\n",
    "    # Model for text data\n",
    "    em = Embedding(max_word_index + 1, 100, input_length = textinput_dimension)(textin) # Current dimension = max_word_index + 1\n",
    "    lstm = LSTM(textinput_dimension)(em) \n",
    "    Dense5 = Dense(50)(lstm)\n",
    "    Dense6 = Dense(20)(Dense5)\n",
    "    # Concatenate value from two previous paths\n",
    "    merged = Concatenate()([Dense4, Dense6])\n",
    "    # Last layer would be softmax\n",
    "    output = Dense(1, activation='sigmoid')(merged)\n",
    "    # Generate model\n",
    "    model = Model(inputs=input_layer, outputs=output)\n",
    "    # Compiling model\n",
    "    model.compile(optimizer='adam', loss='BinaryCrossentropy', metrics=['F1Score'])\n",
    "    # Createing a checkpoint path to automatically save model\n",
    "    checkpoint_path = os.path.join(os.getcwd(), \"num_text_models_new\\cp.ckpt\")\n",
    "    checkpoint_dir = os.path.dirname(checkpoint_path)\n",
    "    # Create a callback that saves the model's weights\n",
    "    cp_callback = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_path,\n",
    "                                                    save_weights_only=True\n",
    "                                                    )\n",
    "    return model, cp_callback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train = data_train.astype('float32')\n",
    "label_train = label_train.astype('float32')\n",
    "data_eval = data_eval.astype('float32')\n",
    "label_eval = label_eval.astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model, cp_callback = get_model(data_train, 200)\n",
    "\n",
    "hist = model.fit(\n",
    "    x= data_train, \n",
    "    y= label_train, \n",
    "    epochs= 10, \n",
    "    batch_size = 2**9, \n",
    "    validation_data = (data_eval,label_eval),\n",
    "    callbacks= [cp_callback]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labeling_evaluating(\n",
    "    label_eval, \n",
    "    model.predict(data_eval), \n",
    "    threshold = 0.5\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Result Summary:**\n",
    "\n",
    "- Neural Network on Non-Text Data: Achieved an accuracy of approximately 0.5.\n",
    "- Neural Network Combined with RNN on Both Text and Non-Text Data: Attained an accuracy of around 0.3.\n",
    "- Reformatted Target, Neural Network on Non-Text Data: Demonstrated an accuracy of roughly 0.65.\n",
    "- Reformatted Target, Neural Network Combined with RNN on Both Text and Non-Text Data: Showed an accuracy of about 0.6.\n",
    "\n",
    "### **Conclusion:**\n",
    "\n",
    "It appears that, with the current approach, predicting the adoption speed for pets is a challenging task.\n",
    "\n",
    "The textual descriptions of the pets do not appear to contribute positively to the model's performance; in fact, they seem to have a detrimental effect.\n",
    "\n",
    "Reformatting the target variable to transform this into a two-label classification problem has led to a slight improvement in the model's performance.\n",
    "\n",
    "However, given the current accuracy and other metrics, it is evident that the model requires substantial improvements and changes to be effective."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
